dat = read.csv('~/Dropbox/lab/SFPCA/bayesianSFPCA/application_ECAM/data/metadata_shannon.txt', sep='\t')
ECAM <- dat
usethis::use_data(ECAM, overwrite = T)
pkgbuild::compile_dll()
devtools::load_all('BayesTime')
setwd("~/Dropbox/lab/SFPCA")
devtools::load_all('BayesTime')
data("ECAM")
sfpca_qqplot(ECAM, 'shannon')
View(ECAM)
devtools::load_all("BayesTime")
sfpca_qqplot(ECAM, 'shannon')
devtools::load_all("BayesTime")
sfpca_qqplot(ECAM, 'shannon')
ECAM <- ECAM[!duplicated(ECAM[, c('studyid', 'month_of_life')]), ]
dat <- prepare_data(ECAM, unique_subject_id = 'studyid', time_name = 'month_of_life',
response_name = 'shannon', transform_y='standardize', scale_time=T)
sfpca_stan_results <- sfpca_stan(dat, Nsamples = 1000, Nchain = 3, 3, 3)
sfpca_stan_results <- sfpca_stan(dat, Nsamples = 1000, Nchain = 2, 2, 3)
optimal_model <- sfpca_optimal(sfpca_stan_results)
setwd("~/Dropbox/lab/SFPCA")
devtools::load_all('BayesTime')
data("ECAM")
sfpca_qqplot(ECAM, 'shannon')
ECAM <- ECAM[!duplicated(ECAM[, c('studyid', 'month_of_life')]), ]
dat <- prepare_data(ECAM, unique_subject_id = 'studyid', time_name = 'month_of_life',
response_name = 'shannon', transform_y='standardize', scale_time=T)
sfpca_stan_results <- sfpca_stan(dat, Nsamples = 1000, Nchain = 3, 2, 3)
sfpca_stan_results <- sfpca_stan(dat, Nsamples = 1000, Nchain = 3, 3, 3)
optimal_model <- sfpca_optimal(sfpca_stan_results)
save(sfpca_stan_results, '~/Dropbox/lab/SFPCA/results_pkg/stan.RData')
save(sfpca_stan_results, file='~/Dropbox/lab/SFPCA/results_pkg/stan.RData')
optimal_model <- sfpca_optimal(sfpca_stan_results)
devtools::load_all("BayesTime")
plot_diagnostic(dat, optimal_model)
devtools::load_all("BayesTime")
plot_diagnostic(dat, optimal_model)
devtools::load_all("BayesTime")
plot_diagnostic(dat, optimal_model)
devtools::load_all("BayesTime")
plot_diagnostic(dat, optimal_model)
results_basis <- (dat, optimal_model$knot,  orth=TRUE)
results_basis <- (dat, optimal_model$knot, orth=TRUE)
results_basis <- basis_setup_sparse(dat, optimal_model$knot, orth=TRUE)
model_basis <- basis_setup_sparse(dat, optimal_model$knot, orth=TRUE)
model_rotation <- post_hoc_rotation(dat, optimal_model)
devtools::load_all("BayesTime")
devtools::load_all("BayesTime")
model_rotation <- post_hoc_rotation(dat, optimal_model)
View(dat)
View(dat)
d <- dat$data
View(d)
devtools::load_all("BayesTime")
invars <- invariants(ECAM, 'studyid', 'month_of_life')
devtools::load_all("BayesTime")
invars <- invariants(ECAM, 'studyid', 'month_of_life')
model_output <- output_results(dat, invars, model_basis, model_rotation)
model_output <- output_results(dat, invars, model_basis, model_rotation)
devtools::load_all("BayesTime")
devtools::load_all("BayesTime")
model_output <- output_results(dat, invars, model_basis, model_rotation)
dat=sfpca_data
dat<-sfpca_data
sfpca_data <- dat
variables<-invars
basis=model_basis
rotation=model_rotation
npcs <- rotation$npcs
ALPHA_array <- rotation$alpha_new
MU_array <- rotation$theta_mu_new
THETA_array <- rotation$Theta_new
phi_t_cont <- basis$orth_spline_basis_cont
phi_t <- basis$orth_spline_basis_sparse
time_cont <- basis$time_cont
N <- sfpca_data$num_subjects
nloop <- dim(ALPHA_array)[3]
first <- 1
last <- nloop
MU_mean <- MU_array[, first] #mean function across sampling sessions
ALPHA_mean <- ALPHA_array[, , first] # mean factor scores
THETA_mean <- THETA_array[, , first] # mean factor loading
for (iter in 2:nloop) {
MU_mean <- MU_mean + MU_array[, iter]
ALPHA_mean <- ALPHA_mean + ALPHA_array[, , iter]
THETA_mean <- THETA_mean + THETA_array[, , iter]
}
MU_mean <- cbind(MU_mean / (last - first + 1))
ALPHA_mean <- cbind(ALPHA_mean / (last - first + 1))
THETA_mean <- cbind(THETA_mean / (last - first + 1))
cbind(phi_t_cont)
Mu_functions <- t(Matrix::bdiag(cbind(phi_t_cont))) %*% MU_mean
setwd("~/Dropbox/lab/Kids")
library(vegan)
library(tidyr)
library(parallel)
library(rstan)
library(foreach)
library(Matrix)
options(mc.cores = parallel::detectCores())
source('Qiime2/code/sfpca_revised.R')
#only keep kids in yonug group
meta <- read.delim('Qiime2/data/11405_prep_3914_qiime_20190424-152313.txt', sep="\t", stringsAsFactors = F)
meta_young <- meta[meta$age_group == 'young', ]
shannon <-read.csv('Qiime2/data/60671-alpha_shannon/alpha-diversity.tsv', stringsAsFactors=FALSE, sep='\t')
data <- merge(meta_young, shannon, by.x = 'X.SampleID', by.y = 'X')
data$age <- as.numeric(data$age)
age_ix <- which(colnames(data)=='age')
var_names <- colnames(data)[age_ix:ncol(data)]
data_invar_names <- get_invariants(data, var_names, 'host_subject_id', 'age_group_month')
#preprocess data
prepared_data = prepare_data(data=data, unique_subject_id = 'host_subject_id', time_var='age',
response='shannon', transform.y='standardize', scale.time=TRUE)
Nsamples = 1000
Nchains = 3
model_file = "Qiime2/code/sfpca2.stan"
smod = stan_model(model_file)
PC_max = 2 # number of PCs
D_max = 2 # number of knots
#save(sfpca_stan_results, file='Qiime2/results/sfpca/stan_shannon_2pc2knots.RData')
load('Qiime2/results/sfpca/stan_shannon_2pc2knots.RData')
sfpca_model <- get_optimal_model(sfpca_stan_results)
results_basis = basis_setup_sparse(prepared_data=prepared_data, sfpca_model$k, orth=TRUE)
results_rotation <- post_hoc_rotation(sfpca_model, prepared_data, Nchains, Nsamples)
results_list <- output_results(prepared_data, data_invar_names, results_rotation, results_basis)
Matrix::bdiag(cbind(phi_t_cont))
t(Matrix::bdiag(cbind(phi_t_cont)))
model_output <- output_results(dat, invars, model_basis, model_rotation)
devtools::load_all("~/Dropbox/lab/SFPCA/BayesTime")
setwd("~/Dropbox/lab/SFPCA")
devtools::load_all('BayesTime')
data("ECAM")
sfpca_qqplot(ECAM, 'shannon')
ECAM <- ECAM[!duplicated(ECAM[, c('studyid', 'month_of_life')]), ]
qqplot(ECAM, 'shannon')
sfpca_qqplot(ECAM, 'shannon')
ECAM <- ECAM[!duplicated(ECAM[, c('studyid', 'month_of_life')]), ]
invars <- invariants(ECAM, 'studyid', 'month_of_life')
dat <- prepare_data(ECAM, unique_subject_id = 'studyid', time_name = 'month_of_life',
response_name = 'shannon', transform_y='standardize', scale_time=T)
load('~/Dropbox/lab/SFPCA/results_pkg/stan.RData')
optimal_model <- optimal(sfpca_stan_results)
plot_diagnostic(dat, optimal_model)
model_basis <- basis_setup_sparse(dat, optimal_model$knot, orth=TRUE)
model_rotation <- post_hoc_rotation(dat, optimal_model)
model_output <- output_results(dat, invars, model_basis, model_rotation)
devtools::load_all("BayesTime")
model_output <- output_results(dat, invars, model_basis, model_rotation)
sfpca_data <- dat
basis=model_basis
rotation=model_rotation
variables=invars
npcs <- rotation$npcs
ALPHA_array <- rotation$alpha_new
MU_array <- rotation$theta_mu_new
THETA_array <- rotation$Theta_new
phi_t_cont <- basis$orth_spline_basis_cont
phi_t <- basis$orth_spline_basis_sparse
time_cont <- basis$time_cont
N <- sfpca_data$num_subjects
nloop <- dim(ALPHA_array)[3]
first <- 1
last <- nloop
MU_mean <- MU_array[, first] #mean function across sampling sessions
ALPHA_mean <- ALPHA_array[, , first] # mean factor scores
THETA_mean <- THETA_array[, , first] # mean factor loading
for (iter in 2:nloop) {
MU_mean <- MU_mean + MU_array[, iter]
ALPHA_mean <- ALPHA_mean + ALPHA_array[, , iter]
THETA_mean <- THETA_mean + THETA_array[, , iter]
}
MU_mean <- cbind(MU_mean / (last - first + 1))
ALPHA_mean <- cbind(ALPHA_mean / (last - first + 1))
THETA_mean <- cbind(THETA_mean / (last - first + 1))
Mu_functions_temp <- Matrix::bdiag(cbind(phi_t_cont))
Mu_functions <- t(Mu_functions_temp) %*% MU_mean
FPC_mean <- t(phi_t_cont) %*% THETA_mean
vars_complete <- c('ID', 'time', 'response', variables)
tryCatch({
df <- sfpca_data$data[, vars_complete]
}, error = function(e){
cat("ERROR :", 'Selected variables not in data', "\n")
})
Mu_functions_temp <- Matrix::bdiag(cbind(phi_t_cont))
Mu_functions <- t(Mu_functions_temp) %*% MU_mean
model_output <- output_results(dat, invars, model_basis, model_rotation)
model_output <- output_results(sfpca_data=dat, variables=invars, basis=model_basis, rotation=model_rotation)
model_output <- output_results(sfpca_data=dat, variables=invars, basis=model_basis, rotation=model_rotation)
Q
model_output <- output_results(sfpca_data=dat, variables=invars, basis=model_basis, rotation=model_rotation)
devtools::load_all("BayesTime")
model_output <- output_results(sfpca_data=dat, variables=invars, basis=model_basis, rotation=model_rotation)
devtools::load_all("BayesTime")
model_output <- output_results(sfpca_data=dat, variables=invars, basis=model_basis, rotation=model_rotation)
devtools::load_all("BayesTime")
model_rda <- sfpca_rda(model_output, optimal_model)
output<-model_output
model=optimal_model
df <- output$df
df <- df[complete.cases(df), ]
if (is.null(variables)){
dat <- df[, -c('ID', 'time')]
} else {
dat <- df[, variables]
}
df[, -c('ID', 'time')]
View(df)
colnames(df) %in% c('ID', 'time')
df[, !colnames(df) %in% c('ID', 'time')]
devtools::load_all("BayesTime")
model_rda <- sfpca_rda(model_output, optimal_model)
model_rda
if (is.null(variables)){
dat <- df[, !colnames(df) %in% c('ID', 'time')]
} else {
dat <- df[, variables]
}
pc.names <- numeric(model$pc)
pc.names <- sapply(1:model$pc, function(i){
paste('fpc', i, sep = '')
})
pc <- df[, pc.names]
View(pc)
mod0 <- vegan::rda(pc ~ 1., dat)  # Model with intercept only
mod1 <- vegan::rda(pc ~ ., dat)  # Model with all explanatory variables
set.seed(111)
step.res <- vegan::ordiR2step(mod0, mod1, perm.max = 1000)
#add effect-size
table <- step.res$anova
if (is.null(table)) return(print('no non-redundant variable'))
table.row <- nrow(table)
R2.adj <- c(table$R2.adj[1])
for (i in 1:(table.row - 1)) {
R2.adj <- c(R2.adj, table$R2.adj[i+1]-table$R2.adj[i])
}
table$ES.RDA <- R2.adj
table <- table[-table.row, ]
print(step.res$call)
covariates <- rownames(table)
ggplot2::ggplot(table, aes(x=reorder(covariates, ES.RDA), y=ES.RDA,
fill=covariates)) +
labs(x = 'Non-redundant Covariants', y = 'Effect Size') +
geom_bar(stat='identity') +
theme(axis.text=element_text(size=10),
axis.title=element_text(size=14,face="bold"),
legend.position="none") +
coord_flip()
dev.off()
ggplot2::ggplot(table, aes(x=reorder(covariates, ES.RDA), y=ES.RDA,
fill=covariates)) +
labs(x = 'Non-redundant Covariants', y = 'Effect Size') +
geom_bar(stat='identity') +
theme(axis.text=element_text(size=10),
axis.title=element_text(size=14,face="bold"),
legend.position="none") +
coord_flip()
model_rda <- sfpca_rda(model_output, optimal_model)
model_rda
View(df)
devtools::load_all("BayesTime")
model_rda <- sfpca_rda(model_output, optimal_model, invars)
model_rda
devtools::load_all("BayesTime")
plot_residual(model_output)
setwd("~/Dropbox/lab/CRIC/code")
install.packages("rmarkdown")
devtools::use_vignette("bayestime-vignette")
usethis::use_vignette("bayestime-vignette")
setwd("~/Dropbox/lab/SFPCA")
setwd("~/Dropbox/lab/SFPCA/BayesTime")
devtools::load_all(".")
setwd("~/Dropbox/lab/SFPCA")
devtools::load_all("BayesTime")
devtools::load_all("BayesTime")
data("ECAM")
setwd("~/Dropbox/lab/SFPCA")
devtools::load_all("BayesTime")
setwd("~/Dropbox/lab/SFPCA/BayesTime")
devtools::load_all("BayesTime")
library(BayesTime)
data("ECAM")
head(ECAM)
#devtools::load_all("BayesTime")
library(BayesTime)
devtools::build(
)
setwd("~/Dropbox/lab/SFPCA")
devtools::load_all("BayesTime")
source('~/Dropbox/lab/SFPCA/BayesTime/R/invariants.R')
source('~/Dropbox/lab/SFPCA/BayesTime/R/invariants.R')
setwd("~/Dropbox/lab/SFPCA")
devtools::load_all('BayesTime')
data("ECAM")
plot_qqplot(ECAM, 'shannon')
ECAM <- ECAM[!duplicated(ECAM[, c('studyid', 'month_of_life')]), ]
devtools::load_all("BayesTime")
rm(list = c("invariants"))
devtools::load_all("BayesTime")
devtools::load_all('BayesTime')
data("ECAM")
plot_qqplot(ECAM, 'shannon')
ECAM <- ECAM[!duplicated(ECAM[, c('studyid', 'month_of_life')]), ]
invars <- invariants(ECAM, 'studyid', 'month_of_life')
dat <- prepare_data(ECAM, unique_subject_id = 'studyid', time_name = 'month_of_life',
response_name = 'shannon', transform_y='standardize', scale_time=T)
load('~/Dropbox/lab/SFPCA/results_pkg/stan.RData')
optimal_model <- optimal(sfpca_stan_results)
plot_diagnostic(dat, optimal_model)
devtools::load_all("BayesTime")
devtools::load_all("BayesTime")
devtools::load_all("BayesTime")
devtools::load_all(".")
devtools::load_all(".")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
devtools::load_all(".")
library(BayesTime)
data("ECAM")
head(ECAM)
plot_qqplot(ECAM, 'shannon')
ECAM <- ECAM[!duplicated(ECAM[, c('studyid', 'month_of_life')]), ]
dat <- prepare_data(data = ECAM, unique_subject_id = 'studyid', time_name = 'month_of_life',
response_name = 'shannon', transform_y = 'standardize', scale_time = T)
summary(dat)
invars <- invariants(ECAM, 'studyid', 'month_of_life')
invars
plot_group(data = ECAM, time_name = 'month_of_life', response_name = 'shannon',
unique_subject_id = 'studyid', group_name = invars)
#sfpca_stan_results <- stan_fit(data = dat, Nsamples = 1000, Nchain = 3,
#                         PC_max = 3, D_max = 3)
load('~/Dropbox/lab/SFPCA/results_pkg/stan.RData')
## optimal(): Get the optimal model
BayesTime::optimal() takes a list of fitted stan models and use loo_compare() from loo package. This prints out the compare results and return the optimal stan model.
```{r}
optimal_model <- optimal(sfpca_stan_results)
summary(optimal_model)
```
plot_k_diagnostic(dat, optimal_model)
data("ECAM")
head(ECAM)
sfpca_data=dat
model=optimal_model
N <- sfpca_data$num_subjects
loo_best <- model$looic
pkdf <- data.frame(pk = loo_best$diagnostics$pareto_k, id = 1:N)
sfpca_stan_results <- stan_fit(data = dat, Nsamples = 1000, Nchain = 3,
PC_max = 3, D_max = 3)
sfpca_stan_results <- stan_fit(data = dat, Nsamples = 1000, Nchain = 3,
PC_max = 3, D_max = 3)
save(sfpca_stan_results, file='~/Dropbox/lab/SFPCA/results_pkg/stan_ECAM.RData')
View(ECAM)
n=10000
x=rnorm(n)
z=rnorm(n)
y=2*x+z+rnorm(n)
fit=lm(y~x+z)
print(coef(fit)[['x']])
with(biostat615, welcome(students))
data=ECAM
unique_subject_id = 'studyid'
time_name = 'month_of_life'
response_name = 'shannon'
transform_y = 'standardize'
scale_time = T
if (!(unique_subject_id %in% colnames(data)) |
!(time_name %in% colnames(data)) |
!(response_name %in% colnames(data))) stop("Variable name is not in data")
# check if each subject has unique measurement at each time point
data_check <- data[, c(as.character(unique_subject_id), as.character(time_name))]
View(data_check)
data_check[duplicated(data_check), ]
duplicated(data_check)
data_duplicate <- data_check[duplicated(data_check), ]
View(data_duplicate)
keys <- colnames(data)[!grepl('shannon',colnames(data))]
X <- as.data.frame(data)
X[,list(mm= mean(shannon)),keys]
X <- as.data.table(data)
data_duplicate <- data_check[duplicated(data_check) | duplicated(data_check, fromLast = T), ]
View(data_duplicate)
data_duplicate <- data_check[duplicated(data_check), ]
View(data_duplicate)
a <- aggregate(shannon,by=list(name=unique_subject_id,etc1=time),data=data,FUN=mean)
a <- aggregate(response_name,by=list(name=unique_subject_id,etc1=time),data=data,FUN=mean)
# check if each subject has unique measurement at each time point
data_check <- data[, c(as.character(unique_subject_id), as.character(time_name), response_name)]
a <- aggregate(response_name,by=list(name=unique_subject_id,etc1=time),data=data_check,FUN=mean)
a <- aggregate(response_name,by=list(unique_subject_id=unique_subject_id,etime=time_name),data=data_check,FUN=mean)
View(a)
View(data_check)
a <- aggregate(response_name,by=list(unique_subject_id=unique_subject_id,time=time_name),data=data_check,FUN=mean)
# check if each subject has unique measurement at each time point
data_check <- data[, c(as.character(unique_subject_id), as.character(time_name), as.numeric(response_name))]
response_name
# check if each subject has unique measurement at each time point
data_check <- data[, c(as.character(unique_subject_id), as.character(time_name), as.numeric(response_name))]
data=ECAM
# check if each subject has unique measurement at each time point
data_check <- data[, c(as.character(unique_subject_id), as.character(time_name), as.numeric(response_name))]
unique_subject_id
time_name
response_name
View(data)
# check if each subject has unique measurement at each time point
data_check <- data[, c(as.character(unique_subject_id), as.character(time_name), as.character(response_name))]
data_check[, response_name] <- as.numeric(data_check[, response_name])
a <- aggregate(response_name,by=list(unique_subject_id=unique_subject_id,time=time_name),data=data_check,FUN=mean)
View(a)
lapply(data_check,class)
a <- aggregate(response_name,data=data_check,FUN=mean)
a <- aggregate(response_name,by=list(unique_subject_id=unique_subject_id),data=data_check,FUN=mean)
View(a)
a <- aggregate(data_check[,response_name],by=list(unique_subject_id=unique_subject_id,time=time_name),data=data_check,FUN=mean)
data_check[,response_name]
a <- aggregate(data_check[,response_name],by=list(unique_subject_id=data_check[,unique_subject_id],
time=data_check[,time_name]),data=data_check,FUN=mean)
View(a)
4.1435515+4.1175688
8.26112/2
duplicated(data_check)
data_unique <- data[!duplicated(data[, c(unique_subject_id, time_name)]), ]
devtools::load_all(".")
devtools::load_all(".")
library(BayesTime)
data("ECAM")
data = ECAM
unique_subject_id = 'studyid'
time_name = 'month_of_life'
response_name = 'shannon'
data_unique <- data[!duplicated(data[, c(unique_subject_id, time_name)])]
unique_subject_id
time_name
data[, c(unique_subject_id, time_name)
]
data_unique <- data[!duplicated(data[, c(unique_subject_id, time_name)]), ]
View(data_unique)
data_duplicate <- data_check[duplicated(data_check) | duplicated(data_check, fromLast = T), ]
# check if each subject has unique measurement at each time point
data_check <- data[, c(as.character(unique_subject_id), as.character(time_name), as.character(response_name))]
#data_duplicate <- data_check[duplicated(data_check), ]
data_duplicate <- data_check[duplicated(data_check) | duplicated(data_check, fromLast = T), ]
#data_duplicate <- data_check[duplicated(data_check), ]
data_duplicate <- data_check[duplicated(data_check) | duplicated(data_check, fromLast = T), ]
#data_duplicate <- data_check[duplicated(data_check), ]
data_duplicate <- data_check[duplicated(data_check[-3]) | duplicated(data_check[-3], fromLast = T), ]
View(data_duplicate)
View(data_check)
install.packages('data.table')
install.packages("data.table")
install.packages("data.table")
install.packages("data.table")
install.packages("data.table")
install.packages("data.table")
library(data.table)
keys <- colnames(dat)[!grepl('shannon',colnames(data))]
keys <- colnames(data)[!grepl('shannon',colnames(data))]
X <- as.data.table(data)
X[,list(mm= mean(shannon)),keys]
unqie <- X[,list(mm= mean(shannon)),keys]
View(unqie)
keys <- colnames(data)[!grepl('shannon',colnames(data))][-1]
X <- as.data.table(data)
unqie <- X[,list(mm= mean(shannon)),keys]
View(unqie)
dupli_ids <- data_check[, unique_subject_id]
dupli_ids <- unique(data_check[, unique_subject_id])
stop(paste('Subject', dupli_ids,
'have duplicate measurements at the same timepoint.'))
paste('Subject', dupli_ids,
'have duplicate measurements at the same timepoint.')
